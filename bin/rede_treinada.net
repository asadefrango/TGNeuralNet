FANN_FLO_2.1
num_layers=2
learning_rate=0.700000
connection_rate=1.000000
network_type=1
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=101 1 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (101, 2, 5.00000000000000000000e-01) 
connections (connected_to_neuron, weight)=(0, 3.35627794265747070312e-03) (1, 2.66083329916000366211e-03) (2, 9.61484983563423156738e-02) (3, -7.47354701161384582520e-02) (4, -8.54680016636848449707e-02) (5, 8.60255137085914611816e-02) (6, 4.26488444209098815918e-02) (7, 6.51472806930541992188e-03) (8, 9.75336059927940368652e-02) (9, -7.27702677249908447266e-03) (10, -8.68483185768127441406e-02) (11, 5.76280131936073303223e-02) (12, -5.83470575511455535889e-02) (13, -6.04341179132461547852e-02) (14, 5.29351308941841125488e-02) (15, 1.70343145728111267090e-02) (16, 8.14677700400352478027e-02) (17, -9.78633686900138854980e-02) (18, -6.63263052701950073242e-02) (19, -4.89497296512126922607e-02) (20, 2.22809687256813049316e-02) (21, 4.29995730519294738770e-02) (22, 1.93596705794334411621e-02) (23, 8.83055850863456726074e-02) (24, -2.80081108212471008301e-02) (25, 4.67538312077522277832e-02) (26, -2.68383324146270751953e-03) (27, -8.85471254587173461914e-02) (28, -1.31509751081466674805e-02) (29, 4.73248437047004699707e-02) (30, 8.33261385560035705566e-02) (31, 9.02053043246269226074e-02) (32, -5.00143356621265411377e-02) (33, 7.94746354222297668457e-02) (34, -8.45301672816276550293e-02) (35, -3.54823321104049682617e-02) (36, 6.55001476407051086426e-02) (37, 5.81186786293983459473e-02) (38, 7.10323974490165710449e-02) (39, 6.30337521433830261230e-02) (40, -4.91583459079265594482e-02) (41, 8.41840729117393493652e-02) (42, 2.06617563962936401367e-02) (43, -7.50540196895599365234e-03) (44, -7.62500390410423278809e-02) (45, -2.64031141996383666992e-02) (46, -9.04710888862609863281e-02) (47, -9.47822704911231994629e-02) (48, -2.42664813995361328125e-02) (49, -5.67973963916301727295e-02) (50, -4.37319986522197723389e-02) (51, 9.80144813656806945801e-02) (52, 8.62021669745445251465e-02) (53, 7.56276771426200866699e-02) (54, 8.63200649619102478027e-02) (55, -4.18059341609477996826e-02) (56, 2.23815068602561950684e-02) (57, -1.63637697696685791016e-02) (58, -3.03530544042587280273e-02) (59, -9.07694697380065917969e-02) (60, -6.90389350056648254395e-02) (61, -4.70269210636615753174e-02) (62, 9.94358286261558532715e-02) (63, -1.90532654523849487305e-02) (64, -6.75522983074188232422e-02) (65, -8.50943326950073242188e-02) (66, 4.54644039273262023926e-02) (67, 9.79478433728218078613e-02) (68, 7.30243399739265441895e-02) (69, 1.64967924356460571289e-02) (70, 6.09815940260887145996e-02) (71, -7.61339962482452392578e-02) (72, 6.80863857269287109375e-04) (73, -1.83566510677337646484e-02) (74, 1.63605958223342895508e-02) (75, 2.44308263063430786133e-02) (76, 5.52402362227439880371e-02) (77, 2.58895084261894226074e-02) (78, 2.96485498547554016113e-02) (79, -6.90262466669082641602e-02) (80, 6.90921023488044738770e-02) (81, 8.59165564179420471191e-02) (82, -7.10117667913436889648e-02) (83, 5.52942827343940734863e-02) (84, 6.15442469716072082520e-02) (85, -8.46917107701301574707e-02) (86, -8.65116491913795471191e-02) (87, -1.60742551088333129883e-02) (88, -1.05547904968261718750e-03) (89, -1.68647095561027526855e-02) (90, -6.84373080730438232422e-03) (91, 2.99055948853492736816e-02) (92, 3.61083671450614929199e-02) (93, -7.40788877010345458984e-03) (94, -8.91476795077323913574e-02) (95, 6.85560777783393859863e-02) (96, 7.49777257442474365234e-03) (97, 5.63167259097099304199e-02) (98, 6.65039196610450744629e-02) (99, -1.94778814911842346191e-02) (100, -2.71864905953407287598e-02) 
